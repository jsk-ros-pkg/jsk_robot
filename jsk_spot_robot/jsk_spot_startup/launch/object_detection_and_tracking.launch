<launch>
  <arg name="INPUT_PANORAMA_IMAGE" default="/dual_fisheye_to_panorama/output/quater" />
  <arg name="INPUT_PANORAMA_INFO" default="/dual_fisheye_to_panorama/panorama_info" />

  <arg name="use_edgetpu" default="true"/>
  <!-- -->
  <arg name="model_file" default="$(find coral_usb)/models/mobilenet_ssd_v2_coco_quant_postprocess_edgetpu.tflite"/>
  <arg name="label_file" default="$(find coral_usb)/models/coco_labels.txt"/>
  <arg name="device_id" default="0" />
  <arg name="n_split" default="3" />
  <arg name="overlap" default="true" />
  <!-- -->
  <arg name="gpu" default="0"/>

  <arg name="TOPIC_OBJ_CLASS" default="/spot_recognition/class" />
  <arg name="TOPIC_OBJ_RECTS" default="/spot_recognition/rects" />

  <!-- EdgeTPU object detection -->
  <node
      pkg="coral_usb"
      type="edgetpu_panorama_object_detector.py"
      name="edgetpu_panorama_object_detector"
      output="screen"
      respawn="true"
      if="$(arg use_edgetpu)"
      >
    <remap from="~input" to="$(arg input_panorama_image)" />
    <remap from="~output/class" to="$(arg TOPIC_OBJ_CLASS)" />
    <remap from="~output/rects" to="$(arg TOPIC_OBJ_RECTS)" />
    <rosparam subst_value="true" >
      score_thresh: 0.8
      model_file: $(arg model_file)
      label_file: $(arg label_file)
      image_transport: raw
      device_id: $(arg device_id)
      n_split: $(arg n_split)
      overlap: $(arg overlap)
    </rosparam>
  </node>
  <!-- GPU object detection -->
  <node
      pkg="jsk_perception"
      type="ssd_object_detector.py"
      name="ssd_object_detector"
      output="screen"
      respawn="true"
      unless="$(arg use_edgetpu)"
      >
    <remap from="~input_panorama_image" to="$(arg input_panorama_image)" />
    <remap from="~output/class" to="$(arg TOPIC_OBJ_CLASS)" />
    <remap from="~output/rects" to="$(arg TOPIC_OBJ_RECTS)" />
    <rosparam subst_value="true">
      gpu: $(arg gpu)
      model_path: voc0712
    </rosparam>
  </node>

  <!-- rects 2 bounding box array -->
  <node
      pkg="jsk_perception"
      type="rect_array_in_panorama_to_bounding_box_array.py"
      name="rect_array_in_panorama_to_bounding_box_array"
      >
    <remap from="~panorama_image" to="/dual_fisheye_to_panorama/output/quater" />
    <remap from="~panorama_info" to="/dual_fisheye_to_panorama/panorama_info" />
    <remap from="~input_class" to="$(arg TOPIC_OBJ_CLASS)" />
    <remap from="~input_rects" to="$(arg TOPIC_OBJ_RECTS)" />
    <rosparam subst_value="true">
        fixed_frame: "odom"
        dimensions_labels:
            person: [0.5, 0.5, 1.5]
    </rosparam>
  </node>

  <!-- multi object tracker -->
  <node
      pkg="jsk_perception"
      type="deep_sort_tracker_node.py"
      name="deep_sort_tracker"
      output="screen"
      clear_params="true"
      unless="$(arg use_object_detector)">
    <remap from="~input" to="$(arg input_panorama_image)" />
    <remap from="~input/rects" to="$(arg TOPIC_OBJ_CLASS)" />
    <remap from="~input/class" to="$(arg TOPIC_OBJ_RECTS)" />
    <rosparam subst_value="true">
      gpu: $(arg gpu)
      pretrained_model: $(find jsk_perception)/trained_data/deepsort_chainermodel.npz
      approximate_sync: True
      slop: 0.3
    </rosparam>
  </node>
</launch>
